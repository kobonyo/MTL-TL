{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import math\n",
    "import os \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset,DataLoader,SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from models import *\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNeXt29_2x64d()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "checkpoint = torch.load('../checkpoint/ckpt.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "print(\"Weigths Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([ \n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomVerticalFlip(p=0.4),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train,X_test,y_test = d['X_train'], d['y_train'],d['X_test'], d['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataLoader(Dataset):\n",
    "    \n",
    "    def __init__(self, datax,datay,transform=None):\n",
    "        self.datax = datax      \n",
    "        self.datay = datay\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.datax)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = self.datax[index]\n",
    "        label = self.datay[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = CustomDataLoader(X_train,y_train,transform=transform_train)\n",
    "test_loader = CustomDataLoader(X_test,y_test,transform=transform_test)\n",
    "data_model_train = DataLoader(train_loader,batch_size=bs,shuffle=True)\n",
    "data_model_test = DataLoader(test_loader,batch_size=bs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):        \n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "def model_head(n=3):\n",
    "    m = list(net.children())[0]\n",
    "    mHead = nn.Sequential(nn.AdaptiveAvgPool2d(2),\n",
    "                          Flatten(),\n",
    "                          nn.Linear(1024*2*2,512),\n",
    "                          nn.BatchNorm1d(512),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                          nn.Linear(512,128),\n",
    "                          nn.BatchNorm1d(128),\n",
    "                          nn.ReLU(inplace=True),\n",
    "                          nn.Linear(128,n),\n",
    "                          nn.Softmax(dim=1))\n",
    "    m = nn.Sequential(*list(m.children())[:-1],\n",
    "                      *list(mHead.children()));\n",
    "    m = m.to(device)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MakeNetwork(nn.Module):\n",
    "    def __init__(self,units):\n",
    "        super(MakeNetwork,self).__init__()\n",
    "        self.units = units\n",
    "        self.model = model_head(units)   \n",
    "    def forward(self,x):          \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MakeNetworks([2]); model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramNet = list(list(agns.children())[0].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(paramNet,lr = 0.0001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,dm):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    agns.train()   \n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    best_acc = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(dm):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)        \n",
    "        optimizer.zero_grad()  \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs[0],targets)                     \n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs[0].max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()  \n",
    "        print('L: %.3f |Ac: %.3f%% .. (%.3f)|'% (train_loss/(batch_idx+1), 100.*correct/total,loss))    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
